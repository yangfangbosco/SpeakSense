# SpeakSense ç¦»çº¿éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ç¡®ä¿ SpeakSense ç³»ç»Ÿåœ¨å®Œå…¨æ–­ç½‘çš„ç¯å¢ƒä¸‹æ­£å¸¸è¿è¡Œã€‚

## å·²å®ç°çš„ç¦»çº¿åŠŸèƒ½

### 1. æœ¬åœ°æ¨¡å‹å­˜å‚¨

æ‰€æœ‰æ¨¡å‹éƒ½å­˜å‚¨åœ¨é¡¹ç›®æœ¬åœ°ï¼Œæ— éœ€ç½‘ç»œè®¿é—®ï¼š

```
SpeakSense/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ CosyVoice2-0.5B/          # CosyVoice2 TTS æ¨¡å‹ (~4.5GB)
â”‚   â”‚   â”œâ”€â”€ llm.pt                # è¯­è¨€æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ flow.pt               # Flow æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ hift.pt               # HiFi-GAN æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ speech_tokenizer_v2.onnx
â”‚   â”‚   â”œâ”€â”€ campplus.onnx         # è¯´è¯äººéªŒè¯
â”‚   â”‚   â”œâ”€â”€ CosyVoice-BlankEN/    # è‹±æ–‡æ¨¡å‹
â”‚   â”‚   â””â”€â”€ reference_speaker.wav # å‚è€ƒéŸ³é¢‘
â”‚   â”‚
â”‚   â””â”€â”€ wetext/                   # æ–‡æœ¬å½’ä¸€åŒ–æ¨¡å‹ (~13MB)
â”‚       â”œâ”€â”€ zh/tn/                # ä¸­æ–‡ TN æ¨¡å‹
â”‚       â”‚   â”œâ”€â”€ tagger.fst
â”‚       â”‚   â””â”€â”€ verbalizer.fst
â”‚       â”œâ”€â”€ en/tn/                # è‹±æ–‡ TN æ¨¡å‹
â”‚       â”‚   â”œâ”€â”€ tagger.fst
â”‚       â”‚   â””â”€â”€ verbalizer.fst
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ third_party/
    â””â”€â”€ CosyVoice/                # CosyVoice ä»£ç åº“
```

### 2. è‡ªåŠ¨æ¨¡å‹åŠ è½½

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼š

```python
# åœ¨ frontend.py ä¸­
if os.path.exists(wetext_model_dir):
    # ä½¿ç”¨æœ¬åœ° wetext æ¨¡å‹
    logging.info(f'Using local wetext model from: {wetext_model_dir}')
else:
    # é™çº§åˆ°åœ¨çº¿ä¸‹è½½ï¼ˆä»…å½“æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨æ—¶ï¼‰
    logging.warning('Local model not found, will download from ModelScope')
```

## ç¦»çº¿éƒ¨ç½²æ£€æŸ¥æ¸…å•

### æ­¥éª¤ 1: éªŒè¯æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å­˜åœ¨

```bash
# æ£€æŸ¥ CosyVoice2 æ¨¡å‹
ls -lh models/CosyVoice2-0.5B/

# åº”è¯¥åŒ…å«ä»¥ä¸‹å…³é”®æ–‡ä»¶ï¼š
# - llm.pt (~1.9GB)
# - flow.pt (~430MB)
# - hift.pt (~80MB)
# - speech_tokenizer_v2.onnx (~473MB)
# - campplus.onnx (~27MB)

# æ£€æŸ¥ wetext æ¨¡å‹
ls -lh models/wetext/

# åº”è¯¥åŒ…å«ï¼š
# - zh/tn/tagger.fst
# - zh/tn/verbalizer.fst
# - en/tn/tagger.fst
# - en/tn/verbalizer.fst
```

### æ­¥éª¤ 2: æµ‹è¯•ç¦»çº¿è¿è¡Œ

```bash
# è¿è¡Œç¦»çº¿æµ‹è¯•è„šæœ¬
python test_offline.py

# é¢„æœŸè¾“å‡ºï¼š
# âœ“ ç¦»çº¿æ¨¡å¼æµ‹è¯•æˆåŠŸï¼
# âœ“ ç³»ç»Ÿå¯ä»¥å®Œå…¨ç¦»çº¿è¿è¡Œï¼
```

### æ­¥éª¤ 3: æ£€æŸ¥æ—¥å¿—

å¯åŠ¨æœåŠ¡åï¼Œæ£€æŸ¥æ—¥å¿—åº”è¯¥çœ‹åˆ°ï¼š

```
INFO Using local wetext model from: .../models/wetext
âœ“ CosyVoice2 model loaded successfully!
```

**ä¸åº”è¯¥çœ‹åˆ°**ï¼š
```
DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
```

## å…¶ä»–ç¦»çº¿ç»„ä»¶

### ASR (Whisper)
- Whisper æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° `~/.cache/whisper/`
- é¦–æ¬¡è¿è¡Œæ—¶éœ€è¦ç½‘ç»œï¼Œä¹‹åå¯ç¦»çº¿ä½¿ç”¨
- æ¨¡å‹å¤§å°ï¼šbase (~140MB)

### å‘é‡æ•°æ®åº“ (ChromaDB)
- å®Œå…¨æœ¬åœ°åŒ–ï¼Œå­˜å‚¨åœ¨ `services/retrieval_service/data/chromadb/`
- æ— éœ€ç½‘ç»œè¿æ¥

### Embedding æ¨¡å‹ (BGE)
- æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° `~/.cache/huggingface/`
- é¦–æ¬¡è¿è¡Œæ—¶éœ€è¦ç½‘ç»œï¼Œä¹‹åå¯ç¦»çº¿ä½¿ç”¨
- æ¨¡å‹: BAAI/bge-small-zh-v1.5 (~100MB)

## å®Œå…¨ç¦»çº¿éƒ¨ç½²æµç¨‹

å¦‚æœéœ€è¦åœ¨**ä»æœªè”ç½‘**çš„æœåŠ¡å™¨ä¸Šéƒ¨ç½²ï¼š

### 1. åœ¨æœ‰ç½‘ç»œçš„æœºå™¨ä¸Šå‡†å¤‡

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository> SpeakSense

# 2. å®‰è£…ä¾èµ–
cd SpeakSense
pip install -r requirements.txt

# 3. è¿è¡Œä¸€æ¬¡ç³»ç»Ÿï¼Œä¸‹è½½æ‰€æœ‰æ¨¡å‹
python test_cosyvoice.py

# 4. æ”¶é›†æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
mkdir offline-models
cp -r models/ offline-models/
cp -r ~/.cache/whisper/ offline-models/whisper/
cp -r ~/.cache/huggingface/ offline-models/huggingface/
cp -r ~/.cache/modelscope/ offline-models/modelscope/
```

### 2. åœ¨ç¦»çº¿æœåŠ¡å™¨ä¸Šéƒ¨ç½²

```bash
# 1. å¤åˆ¶é¡¹ç›®å’Œæ¨¡å‹
scp -r SpeakSense/ offline-server:/path/
scp -r offline-models/ offline-server:/path/

# 2. åœ¨ç¦»çº¿æœåŠ¡å™¨ä¸Šæ¢å¤æ¨¡å‹
cd /path/SpeakSense/
mkdir -p ~/.cache/
cp -r /path/offline-models/whisper ~/.cache/
cp -r /path/offline-models/huggingface ~/.cache/
cp -r /path/offline-models/modelscope ~/.cache/

# 3. æµ‹è¯•ç¦»çº¿è¿è¡Œ
python test_offline.py

# 4. å¯åŠ¨æœåŠ¡
./run_all_services.sh
```

## éªŒè¯ç¦»çº¿è¿è¡Œ

### æ–¹æ³• 1: ç½‘ç»œç›‘æ§

```bash
# å¯åŠ¨æœåŠ¡
./run_all_services.sh

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§ç½‘ç»œè¿æ¥
lsof -i -P | grep python

# åº”è¯¥åªçœ‹åˆ°æœ¬åœ°ç«¯å£ (8001, 8002, 8003)ï¼Œæ²¡æœ‰å¤–éƒ¨è¿æ¥
```

### æ–¹æ³• 2: é˜²ç«å¢™è§„åˆ™

```bash
# ä¸´æ—¶ç¦ç”¨å¤–ç½‘è®¿é—®
sudo pfctl -e  # macOS
# æˆ–
sudo iptables -A OUTPUT -p tcp --dport 80 -j DROP   # Linux
sudo iptables -A OUTPUT -p tcp --dport 443 -j DROP

# æµ‹è¯•ç³»ç»ŸåŠŸèƒ½
curl http://localhost:8003/admin/preview_audio?text=æµ‹è¯•

# æ¢å¤ç½‘ç»œ
sudo pfctl -d  # macOS
# æˆ–
sudo iptables -F OUTPUT  # Linux
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜: ä»ç„¶çœ‹åˆ° ModelScope è¿æ¥

**ç—‡çŠ¶**:
```
DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
```

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ wetext æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼š`ls models/wetext/`
2. æ£€æŸ¥ frontend.py æ˜¯å¦å·²ä¿®æ”¹ï¼š`grep "local wetext" third_party/CosyVoice/cosyvoice/cli/frontend.py`
3. é‡å¯æœåŠ¡ï¼š`./stop_all_services.sh && ./run_all_services.sh`

### é—®é¢˜: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No such file or directory: '.../models/wetext/zh/tn/tagger.fst'
```

**è§£å†³æ–¹æ¡ˆ**:
1. é‡æ–°å¤åˆ¶ wetext æ¨¡å‹ï¼š
   ```bash
   cp -r ~/.cache/modelscope/hub/pengzhendong/wetext models/
   ```
2. éªŒè¯æ–‡ä»¶ç»“æ„ï¼š
   ```bash
   find models/wetext -name "*.fst"
   ```

## æ€§èƒ½ä¼˜åŒ–

ç¦»çº¿éƒ¨ç½²æ—¶çš„æ€§èƒ½å»ºè®®ï¼š

1. **ä½¿ç”¨ SSD**: æ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨ SSD å­˜å‚¨
2. **é¢„çƒ­æ¨¡å‹**: é¦–æ¬¡å¯åŠ¨ä¼šåŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼Œéœ€è¦ 20-30 ç§’
3. **å†…å­˜è¦æ±‚**: å»ºè®®è‡³å°‘ 8GB RAMï¼ˆCosyVoice2 éœ€è¦ ~2GBï¼‰
4. **CPU æ¨ç†**: åœ¨ CPU ä¸Š RTF (Real-Time Factor) çº¦ä¸º 5-7ï¼Œå³ç”Ÿæˆ 1 ç§’éŸ³é¢‘éœ€è¦ 5-7 ç§’

## æ›´æ–°è¯´æ˜

- **ç‰ˆæœ¬**: v1.0 (2025-11-19)
- **CosyVoice2 ç‰ˆæœ¬**: 0.5B
- **wetext ç‰ˆæœ¬**: 0.0.4
- **æµ‹è¯•çŠ¶æ€**: âœ“ å·²éªŒè¯å®Œå…¨ç¦»çº¿è¿è¡Œ

## æ€»ç»“

âœ… **å·²å®ç°ç¦»çº¿åŠŸèƒ½**:
- [x] CosyVoice2 TTS æ¨¡å‹æœ¬åœ°åŒ–
- [x] wetext æ–‡æœ¬å½’ä¸€åŒ–æ¨¡å‹æœ¬åœ°åŒ–
- [x] è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
- [x] ç¦»çº¿æµ‹è¯•è„šæœ¬éªŒè¯

âš ï¸ **é¦–æ¬¡éƒ¨ç½²æ³¨æ„äº‹é¡¹**:
- Whisperã€BGE embedding æ¨¡å‹éœ€è¦é¦–æ¬¡è”ç½‘ä¸‹è½½
- ä¸‹è½½åå¯æ°¸ä¹…ç¦»çº¿ä½¿ç”¨
- å»ºè®®åœ¨æœ‰ç½‘ç»œç¯å¢ƒä¸‹å®Œæˆåˆå§‹åŒ–

ğŸ¯ **ç¦»çº¿éƒ¨ç½²æˆåŠŸæ ‡å¿—**:
- æ—¥å¿—æ˜¾ç¤º "Using local wetext model"
- æ—  modelscope.cn ç½‘ç»œè¿æ¥
- test_offline.py æµ‹è¯•é€šè¿‡
